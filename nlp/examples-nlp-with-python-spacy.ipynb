{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP with Python spaCy: analyzing restaurant reviews\n",
    "\n",
    "\n",
    "_This work is licensed under a [Creative Commons BY-SA 4.0 License](http://creativecommons.org/licenses/by-sa/4.0/)_\n",
    "\n",
    "<br><br><br><br>\n",
    "__Daniel Kapitan__<br>\n",
    "`e. d.kapitan@jads.nl`<br>\n",
    "`w. https://kapitan.net`<br>\n",
    "\n",
    "\n",
    "\n",
    "<img style=\"float: left\" src=\"https://github.com/jads-nl/public-lectures/blob/main/logos/jads-gold-250x60.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The challenge: predict the next Michelin star\n",
    "\n",
    "Thanks to [the people at analyticslab.nl](https://www.theanalyticslab.nl/about-us/) we will use a restaurant review dataset with nearly 370.000 reviews collected over an eight-year period. Using the dataset which they have scraped, we will follow along [their blogpost series](https://www.theanalyticslab.nl/nlpblogs_0_preparing_restaurant_review_data_for_nlp_and_predictive_modeling/), but replacing their R code with a workflow in Python spaCy.\n",
    "\n",
    "In this notebook we compare different NLP techniques to show you how we get valuable information from unstructured text. Given the restaurant reviews, the challenge is whether 'the wisdom of the croud' - reviews from restaurant visitors - could be used to predict which restaurants are most likely to receive a new Michelin-star. We will try to see how that worked out. To following tools and techniques will be demonstrated:\n",
    "\n",
    "- How to setup a reproducible text pipeline in Python spaCy for text analysis;\n",
    "- How to apply [topic modeling](http://www.cs.columbia.edu/~blei/papers/Blei2012.pdf) as the primary tool to extract information from the review texts, to be combined and used in predictive modeling techniques to end up with our predictions.\n",
    "- How two more novel NLP techniques cabn \n",
    " To answer these questions, we will explain our approach in more detail in the coming articles. But we didn't stop exploring NLP techniques after our publication, and we also like to share insights from adding more novel NLP techniques. More specifically we will use two types of word embeddings - a classic [Word2Vec model](https://arxiv.org/abs/1301.3781) and a GLoVe embedding model - we'll use transfer learning with pretrained word embeddings and we use BERT. We compare the added value of these advanced NLP techniques to our baseline topic model on the same dataset. By showing what we did and how we did it, we hope to guide others that are keen to use textual data for their own data science endeavours.\n",
    "\n",
    "\n",
    "## Data preparation\n",
    "Before we delve into the analytical side of things, we need some prepared textual data. As all true data scientists know, proper data preparation takes most of your time and is most decisive for the quality of the analysis results you end up with. Since preparing textual data is another cup of tea compared to preparing structured numeric or categorical data, and our goal is to show you how to do text analytics, we also want to show you how we cleaned and prepared the data we gathered. Therefore, in this notebook we start with the data dump with all reviews and explore and prepare this data in a number of steps:\n",
    "\n",
    "![](https://bhciaaablob.blob.core.windows.net/thefork/Text%20preprocessing%20pipeline_noheader.png)\n",
    "\n",
    "As a result of these steps, we end up with - aside from building insights in our data and some cleaning - a number of flat files we can use as source files throughout the rest of the articles:\n",
    "\n",
    "- __reviews.csv__: a csv file with review texts (original and cleaned) - the fuel for our NLP analyses. (included key: restoreviewid, hence the unique identifier for a review)\n",
    "- __labels.csv__: a csv file with 1 / 0 values, indicating whether the review is a review for a Michelin restaurant or not (included key: restoreviewid)\n",
    "- __restoid.csv__: a csv file with restaurant id's, to be able to determine which reviews belong to which restaurant (included key: restoreviewid)\n",
    "- __trainids.csv__: a csv file with 1 / 0 values, indicating whether the review should be used for training or testing - we already split the reviews in train/test to enable reuse of the same samples for fair comparisons between techniques (included key: restoreviewid)\n",
    "- __features.csv__: a csv file with other features regarding the reviews (included key: restoreviewid)\n",
    "\n",
    "These files with the cleaned and relevant data for NLP techniques are made available to you via public blob storage so that you can run all code we present yourself and see how things work in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 368529 entries, 0 to 368528\n",
      "Data columns (total 25 columns):\n",
      " #   Column               Non-Null Count   Dtype   \n",
      "---  ------               --------------   -----   \n",
      " 0   restoId              368529 non-null  int64   \n",
      " 1   restoName            368529 non-null  object  \n",
      " 2   tags                 356517 non-null  object  \n",
      " 3   address              368529 non-null  object  \n",
      " 4   scoreTotal           348081 non-null  float64 \n",
      " 5   avgPrice             336224 non-null  object  \n",
      " 6   numReviews           368529 non-null  int64   \n",
      " 7   scoreFood            347984 non-null  float64 \n",
      " 8   scoreService         347984 non-null  float64 \n",
      " 9   scoreDecor           348037 non-null  float64 \n",
      " 10  review_id            368529 non-null  float64 \n",
      " 11  numreviews2          368529 non-null  float64 \n",
      " 12  valueForPriceScore   296774 non-null  object  \n",
      " 13  noiseLevelScore      296902 non-null  object  \n",
      " 14  waitingTimeScore     296902 non-null  object  \n",
      " 15  reviewerId           368529 non-null  float64 \n",
      " 16  reviewerFame         365533 non-null  object  \n",
      " 17  reviewerNumReviews   368529 non-null  float64 \n",
      " 18  reviewDate           368529 non-null  object  \n",
      " 19  reviewScoreOverall   368529 non-null  float64 \n",
      " 20  reviewScoreFood      368529 non-null  float64 \n",
      " 21  reviewScoreService   368529 non-null  float64 \n",
      " 22  reviewScoreAmbiance  368529 non-null  float64 \n",
      " 23  reviewText           368529 non-null  object  \n",
      " 24  reviewYear           368529 non-null  category\n",
      "dtypes: category(1), float64(12), int64(2), object(10)\n",
      "memory usage: 67.8+ MB\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import pendulum\n",
    "\n",
    "\n",
    "# # not needed for this notebook, required for uploading data to GitHub in smaller files < 25 MB\n",
    "# REVIEWS = (\n",
    "#     \"https://bhciaaablob.blob.core.windows.net/cmotionsnlpblogs/RestoReviewRawdata.csv\"\n",
    "# )\n",
    "# resto = pd.read_csv(REVIEWS, decimal=\",\")\n",
    "# resto['reviewYear'] = resto.reviewDate.str[-4:].astype('float').astype('Int64')\n",
    "# resto.to_parquet('data/restaurant-reviews', partition_cols=['reviewYear'])\n",
    "\n",
    "raw_reviews = pd.read_parquet(\"data/restaurant-reviews\")\n",
    "raw_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some `reviewText`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    b'We komen al meer dan 8 jaar in dit restauran...\n",
       "1    b'Een werkelijk prachtige ijssalon,blinkende u...\n",
       "2    b'Naast dat men hier heerlijk grieks eten heef...\n",
       "3    b'Via de Sweetdeal genoten van het 3 gangenkeu...\n",
       "4    b'Vakantieveiling is een leuk ding om restaura...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_reviews.reviewText.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, there's clearly some cleaning to be done here.\n",
    "\n",
    "First of all, the available texts are all encapsulated in \"b'...''\", indicating the texts are byte literals. Also you might spot some strange sequences of tokens like in 'ingredi\\xc3\\xabnten', indicating that our texts include UTF-8 encoded tokens (here, the character Ã« that has the code \\xc3\\xab in UTF-8). This combination of byte literal encapsulation with the UTF-8 codes shows that in the creation of the source data we have available, the encoding got messed up a bit, making it difficult to to obtain the review texts out of the encoded data. We won't go in to too much detail here (if you want, read [this](https://diveintopython3.net/strings.html)) but you might run into similar stuff when you start working with textual data. In short, there are different encoding types and you need to know what you are working with. We need to make sure we use the right encoding and we should get rid of the \"b'...''\" in the strings.\n",
    "\n",
    "We could spend some time on figuring out how to correct this messing-up due to coding as good as possible. However, in order not to lose too much time and effort on undoing this (and we don't) we can take a short cut with minimal loss of data by cleaning the texts with some regular expressions. Depending on your goal, you might want to go the extra mile and try to restore the texts in their original UTF-8 encoding though! As so often in data science projects, we're struggling with available time and resources: You need to pick you battles - and pick them wisely!\n",
    "\n",
    "Do we have other things to cover? To get a better understanding of our data, let's check the most frequent, identical review texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'- Recensie is momenteel in behandeling -'    0.003937\n",
       "b'Heerlijk gegeten!'                           0.001037\n",
       "b'Heerlijk gegeten'                            0.000795\n",
       "b'Heerlijk gegeten.'                           0.000448\n",
       "b'Top'                                         0.000293\n",
       "Name: reviewText, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_reviews.reviewText.value_counts(normalize=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, several things to solve here:\n",
    "\n",
    "- About 3% of all reviews have no review text so they are not useful and we can delete those.\n",
    "- Another 0,4% has the value \"b'- Recensie is momenteel in behandeling -'\" (In English: The review is currently being processed) and therefore the actual review text is not published yet. Similar to empty reviews, we can delete these reviews.\n",
    "- Several reviews seem very short and are not that helpful in trying to learn from the review text. Although this is very context dependent (when performing sentiment analysis, short reviews like 'Top!' (English: Top!), 'Prima' (Engish: Fine/OK) and 'Heerlijk gegeten' (En: Had a nice meal) might still have much value!) we will set a minimum length to reviews.\n",
    "\n",
    "We will deal with punctuation later in spaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern matching with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def fix_bytestring(string):\n",
    "    \"\"\"Decode wonky byte string into proper string\"\"\"\n",
    "\n",
    "    pattern = re.compile(r\"^b'(.*)'\")\n",
    "    match = re.search(pattern, string)\n",
    "    if match:\n",
    "        return match[1].encode(\"utf-8\").decode(\"utf-8\")\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    We komen al meer dan 8 jaar in dit restaurant ...\n",
       "1    Een werkelijk prachtige ijssalon,blinkende uit...\n",
       "2    Naast dat men hier heerlijk grieks eten heeft,...\n",
       "3    Via de Sweetdeal genoten van het 3 gangenkeuze...\n",
       "4    Vakantieveiling is een leuk ding om restaurant...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = raw_reviews.loc[:, ['restoId', 'reviewerId', 'review_id', 'reviewerFame', 'reviewerNumReviews']].copy()\n",
    "reviews['reviewText'] = raw_reviews.reviewText.apply(fix_bytestring)\n",
    "reviews.reviewText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            0.956331\n",
       "- Recensie is momenteel in behandeling -    0.035183\n",
       "Top                                         0.002619\n",
       ".                                           0.000970\n",
       "Nvt                                         0.000679\n",
       "-                                           0.000485\n",
       "..                                          0.000291\n",
       "Kip                                         0.000218\n",
       "Ok                                          0.000218\n",
       "nvt                                         0.000218\n",
       "Name: reviewText, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate_review(review):\n",
    "    if review == '- Recensie is momenteel in behandeling -' or len(review) < 4:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "reviews['is_valid'] = reviews.reviewText.apply(validate_review)\n",
    "reviews[reviews.is_valid==0]['reviewText'].value_counts(normalize=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that looks OK, we can safely delete `is_valid == 0` reviews later. Let's do some more data prep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse localized datestrings with `pendulum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9 sep. 1973'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pendulum\n",
    "\n",
    "\n",
    "pendulum.set_locale('nl')\n",
    "pendulum.date(1973, 9, 9).format('D MMM YYYY')  # example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(date):\n",
    "    return pendulum.from_format(date, fmt='D MMM YYYY', locale='nl')\n",
    "\n",
    "reviews['reviewDate'] = raw_reviews.reviewDate.apply(parse_date).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2012-09-19\n",
       "1    2012-07-12\n",
       "2    2012-11-29\n",
       "3    2012-12-13\n",
       "4    2012-10-19\n",
       "Name: reviewDate, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.reviewDate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avgPrice has whitespace and euro character\n",
    "def clean_price(string):\n",
    "    if string:\n",
    "        return string.split(\" \")[-1]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "reviews[\"avgPrice\"] = raw_reviews[\"avgPrice\"].apply(clean_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn categorical columns into ordinal values, lower is better\n",
    "# note to Dutch audience: do you think the ordinal order is sensible and correct?\n",
    "map_scores = {\n",
    "    \"waitingTimeScore\": {\n",
    "        \"Hoog tempo\": 1,\n",
    "        \"Kort\": 2,\n",
    "        \"Redelijk\": 3,\n",
    "        \"Kan beter\": 4,\n",
    "        \"Lang\": 5,\n",
    "    },\n",
    "    \"valueForPriceScore\": {\n",
    "        \"Erg gunstig\": 1,\n",
    "        \"Gunstig\": 2,\n",
    "        \"Redelijk\": 3,\n",
    "        \"Precies goed\": 4,\n",
    "        \"Kan beter\": 5,\n",
    "    },\n",
    "    \"noiseLevelScore\": {\n",
    "        \"Erg rustig\": 1,\n",
    "        \"Rustig\": 2,\n",
    "        \"Precies goed\": 3,\n",
    "        \"Rumoerig\": 4,\n",
    "    },\n",
    "}\n",
    "\n",
    "for col in map_scores.keys():\n",
    "    reviews[col] = (\n",
    "        raw_reviews[col].apply(lambda x: map_scores[col].get(x, None)).astype(\"Int64\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical columns have comma as decimal seperator --> cast to floats\n",
    "numerical_cols = [\n",
    "    \"scoreFood\",\n",
    "    \"scoreService\",\n",
    "    \"scoreDecor\",\n",
    "    \"reviewScoreOverall\",\n",
    "    \"scoreTotal\",\n",
    "]\n",
    "for col in numerical_cols:\n",
    "    reviews[col] = pd.to_numeric(raw_reviews[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restoId</th>\n",
       "      <th>reviewerId</th>\n",
       "      <th>review_id</th>\n",
       "      <th>reviewerFame</th>\n",
       "      <th>reviewerNumReviews</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>reviewDate</th>\n",
       "      <th>avgPrice</th>\n",
       "      <th>waitingTimeScore</th>\n",
       "      <th>valueForPriceScore</th>\n",
       "      <th>noiseLevelScore</th>\n",
       "      <th>scoreFood</th>\n",
       "      <th>scoreService</th>\n",
       "      <th>scoreDecor</th>\n",
       "      <th>reviewScoreOverall</th>\n",
       "      <th>scoreTotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236127</td>\n",
       "      <td>111373143.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Fijnproever</td>\n",
       "      <td>4.0</td>\n",
       "      <td>We komen al meer dan 8 jaar in dit restaurant ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-19</td>\n",
       "      <td>35</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>246631</td>\n",
       "      <td>111355027.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Meesterproever</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Een werkelijk prachtige ijssalon,blinkende uit...</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-07-12</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>243427</td>\n",
       "      <td>112961389.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Expertproever</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Naast dat men hier heerlijk grieks eten heeft,...</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-11-29</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>234077</td>\n",
       "      <td>111347867.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>Meesterproever</td>\n",
       "      <td>97.0</td>\n",
       "      <td>Via de Sweetdeal genoten van het 3 gangenkeuze...</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-12-13</td>\n",
       "      <td>45</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240845</td>\n",
       "      <td>112167929.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Meesterproever</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Vakantieveiling is een leuk ding om restaurant...</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-19</td>\n",
       "      <td>43</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   restoId   reviewerId  review_id    reviewerFame  reviewerNumReviews  \\\n",
       "0   236127  111373143.0       20.0     Fijnproever                 4.0   \n",
       "1   246631  111355027.0       11.0  Meesterproever                21.0   \n",
       "2   243427  112961389.0        3.0   Expertproever                 9.0   \n",
       "3   234077  111347867.0      107.0  Meesterproever                97.0   \n",
       "4   240845  112167929.0       14.0  Meesterproever                40.0   \n",
       "\n",
       "                                          reviewText  is_valid  reviewDate  \\\n",
       "0  We komen al meer dan 8 jaar in dit restaurant ...         1  2012-09-19   \n",
       "1  Een werkelijk prachtige ijssalon,blinkende uit...         1  2012-07-12   \n",
       "2  Naast dat men hier heerlijk grieks eten heeft,...         1  2012-11-29   \n",
       "3  Via de Sweetdeal genoten van het 3 gangenkeuze...         1  2012-12-13   \n",
       "4  Vakantieveiling is een leuk ding om restaurant...         1  2012-10-19   \n",
       "\n",
       "  avgPrice  waitingTimeScore  valueForPriceScore  noiseLevelScore  scoreFood  \\\n",
       "0       35              <NA>                <NA>             <NA>        8.6   \n",
       "1     None              <NA>                <NA>             <NA>        8.2   \n",
       "2     None              <NA>                <NA>             <NA>        NaN   \n",
       "3       45              <NA>                <NA>             <NA>        8.0   \n",
       "4       43              <NA>                <NA>             <NA>        7.3   \n",
       "\n",
       "   scoreService  scoreDecor  reviewScoreOverall  scoreTotal  \n",
       "0           8.4         7.2                 8.5         8.4  \n",
       "1           7.6         8.0                10.0         8.0  \n",
       "2           NaN         NaN                 8.0         NaN  \n",
       "3           8.0         7.6                 7.0         7.9  \n",
       "4           7.6         7.4                 8.5         7.4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: perform exploratory data analysis\n",
    "\n",
    "Prior to diving into NLP with spaCy, perform a EDA to explore possible correlations:\n",
    "- reviewer type vs. given scores\n",
    "- length of reviews vs. scores\n",
    "- value-for-money vs\n",
    "\n",
    "Learning objective:\n",
    "- Lest you forget to always do a short EDA, before getting lost in details ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing in spaCy\n",
    "\n",
    "To develop reproducible pipelines, we will follow the recommended workflow from spaCy.\n",
    "\n",
    "![](https://spacy.io/pipeline-fde48da9b43661abcdf62ab70a546d71.svg)\n",
    "\n",
    "When you call `nlp` on a text, spaCy first tokenizes the text to produce a `Doc` object. The `Doc` is then processed in several different steps â this is also referred to as the __processing pipeline__. The pipeline used by the [trained pipelines](https://spacy.io/models) typically include a tagger, a lemmatizer, a parser and an entity recognizer. Each pipeline component returns the processed `Doc`, which is then passed on to the next component.\n",
    "\n",
    "The tokenizer is a âspecialâ component and isnât part of the regular pipeline. It also doesnât show up in `nlp.pipe_names`. The reason is that there can only really be one tokenizer, and while all other pipeline components take a `Doc` and return it, the tokenizer takes a __string of text__ and turns it into a `Doc`. You can still customize the tokenizer, though. `nlp.tokenizer` is writable, so you can either create your own [`Tokenizer` class from scratch](https://spacy.io/usage/linguistic-features#native-tokenizers), or even replace it with an [entirely custom function](https://spacy.io/usage/linguistic-features#custom-tokenizer).\n",
    "\n",
    "We will use the large Dutch model which is 546 MB in size. The download command needs to be run once on your system. You may want to restart your Jupyter Notebook kernel to ensure spaCy is loaded properly with the newly downloaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nl_core_news_lg==2.3.0 from https://github.com/explosion/spacy-models/releases/download/nl_core_news_lg-2.3.0/nl_core_news_lg-2.3.0.tar.gz#egg=nl_core_news_lg==2.3.0 in /home/dkapitan/.local/lib/python3.8/site-packages (2.3.0)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/dkapitan/.local/lib/python3.8/site-packages (from nl_core_news_lg==2.3.0) (2.3.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/dkapitan/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->nl_core_news_lg==2.3.0) (1.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/dkapitan/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->nl_core_news_lg==2.3.0) (0.7.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/dkapitan/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->nl_core_news_lg==2.3.0) (1.19.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/dkapitan/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->nl_core_news_lg==2.3.0) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/lib/python3/dist-packages (from spacy<2.4.0,>=2.3.0->nl_core_news_lg==2.3.0) (2.23.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/dkapitan/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->nl_core_news_lg==2.3.0) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<2.4.0,>=2.3.0->nl_core_news_lg==2.3.0) (49.3.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/dkapitan/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->nl_core_news_lg==2.3.0) (4.55.1)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/dkapitan/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->nl_core_news_lg==2.3.0) (7.4.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/dkapitan/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->nl_core_news_lg==2.3.0) (0.8.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/dkapitan/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->nl_core_news_lg==2.3.0) (3.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/dkapitan/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->nl_core_news_lg==2.3.0) (2.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/dkapitan/.local/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->nl_core_news_lg==2.3.0) (1.0.0)\n",
      "\u001b[38;5;2mâ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('nl_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download nl_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"nl_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
