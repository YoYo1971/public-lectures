#  Introduction to Natural Language Processing (NLP) with Python spaCy

## Learning objectives
- Understand the basic concepts of probabilistic language models and how these can be applied to different NLP tasks including sentiment analysis, genre classification and named-entity recognition
- Understand and know how to apply n-grams and word embeddings for feature extraction in a classification pipeline
- Have a conceptual understanding of transformers and deep learning techniques for NLP
- Understand and know how to use Python spaCy for NLP and develop reproducible text processing pipelines

## Prerequisites
It is recommended to study the following material prior to the lecture:
- [Illustrated word2vec](http://jalammar.github.io/illustrated-word2vec/) by [Jay Alammar](http://jalammar.github.io/)
- [word2vec explained](https://israelg99.github.io/2017-03-23-Word2Vec-Explained/) by Julian Gilyadov (more technical)
- RealPython.com tutorial [NLP with spaCy in Python](https://realpython.com/natural-language-processing-spacy-python/)

## Recommended materials for further study

### Tutorials
- spaCy's [online course](https://course.spacy.io/en/)
- Dataquest tutorial [Text Classification in Python Using spaCy](https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/)
- Kaggle notebook [Topic modelling with spaCy and scikit-learn](https://www.kaggle.com/thebrownviking20/topic-modelling-with-spacy-and-scikit-learn)

### Theory
[Artificial Intelligence: A Modern Approach (4th edition)](http://aima.cs.berkeley.edu/) provides a thorough overview in two chapters:
- chapter 23 Natural Language Processing explains language models, grammars and parsing
- chapter 24: Deep Learning for NLP explains word embeddings, RNNs, sequence2sequence models, transformers and transfer learning

You need to buy the book, not cheap, but warmly recommended as a desk reference.
